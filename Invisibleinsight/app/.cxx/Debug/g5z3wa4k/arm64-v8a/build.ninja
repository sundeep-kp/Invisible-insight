# CMAKE generated file: DO NOT EDIT!
# Generated by "Ninja" Generator, CMake Version 3.22

# This file contains all the build statements describing the
# compilation DAG.

# =============================================================================
# Write statements declared in CMakeLists.txt:
# 
# Which is the root file.
# =============================================================================

# =============================================================================
# Project: invisibleinsight-native
# Configurations: Debug
# =============================================================================

#############################################
# Minimal version of Ninja required by this file

ninja_required_version = 1.5


#############################################
# Set configuration variable for custom commands.

CONFIGURATION = Debug
# =============================================================================
# Include auxiliary files.


#############################################
# Include rules file.

include CMakeFiles/rules.ninja

# =============================================================================

#############################################
# Logical path to working directory; prefix for absolute paths.

cmake_ninja_workdir = C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/.cxx/Debug/g5z3wa4k/arm64-v8a/
# =============================================================================
# Object build statements for SHARED_LIBRARY target native-lib


#############################################
# Order-only phony target for native-lib

build cmake_object_order_depends_target_native-lib: phony || cmake_object_order_depends_target_build_info cmake_object_order_depends_target_common cmake_object_order_depends_target_cpp-httplib cmake_object_order_depends_target_ggml cmake_object_order_depends_target_ggml-base cmake_object_order_depends_target_ggml-cpu cmake_object_order_depends_target_llama

build CMakeFiles/native-lib.dir/native-lib.cpp.o: CXX_COMPILER__native-lib_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/native-lib.cpp || cmake_object_order_depends_target_native-lib
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB -Dnative_lib_EXPORTS
  DEP_FILE = CMakeFiles\native-lib.dir\native-lib.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor"
  OBJECT_DIR = CMakeFiles\native-lib.dir
  OBJECT_FILE_DIR = CMakeFiles\native-lib.dir


# =============================================================================
# Link build statements for SHARED_LIBRARY target native-lib


#############################################
# Link the shared library C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\build\intermediates\cxx\Debug\g5z3wa4k\obj\arm64-v8a\libnative-lib.so

build C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/build/intermediates/cxx/Debug/g5z3wa4k/obj/arm64-v8a/libnative-lib.so: CXX_SHARED_LIBRARY_LINKER__native-lib_Debug CMakeFiles/native-lib.dir/native-lib.cpp.o | llama.cpp/common/libcommon.a bin/libllama.so bin/libggml.so bin/libggml-cpu.so bin/libggml-base.so llama.cpp/vendor/cpp-httplib/libcpp-httplib.a || bin/libggml-base.so bin/libggml-cpu.so bin/libggml.so bin/libllama.so llama.cpp/common/build_info llama.cpp/common/libcommon.a llama.cpp/vendor/cpp-httplib/libcpp-httplib.a
  LANGUAGE_COMPILE_FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info
  LINK_FLAGS = -static-libstdc++ -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--no-undefined-version -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments
  LINK_LIBRARIES = llama.cpp/common/libcommon.a  -landroid  -llog  bin/libllama.so  bin/libggml.so  bin/libggml-cpu.so  bin/libggml-base.so  llama.cpp/vendor/cpp-httplib/libcpp-httplib.a  -pthread  -latomic -lm
  OBJECT_DIR = CMakeFiles\native-lib.dir
  POST_BUILD = cd .
  PRE_LINK = cd .
  SONAME = libnative-lib.so
  SONAME_FLAG = -Wl,-soname,
  TARGET_FILE = "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\build\intermediates\cxx\Debug\g5z3wa4k\obj\arm64-v8a\libnative-lib.so"
  TARGET_PDB = native-lib.so.dbg


#############################################
# Utility command for edit_cache

build CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build edit_cache: phony CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" --regenerate-during-build -S"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\src\main\cpp" -B"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build rebuild_cache: phony CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build list_install_components: phony


#############################################
# Utility command for install

build CMakeFiles/install.util: CUSTOM_COMMAND all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build install: phony CMakeFiles/install.util


#############################################
# Utility command for install/local

build CMakeFiles/install/local.util: CUSTOM_COMMAND all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build install/local: phony CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build CMakeFiles/install/strip.util: CUSTOM_COMMAND all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build install/strip: phony CMakeFiles/install/strip.util

# =============================================================================
# Write statements declared in CMakeLists.txt:
# C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/CMakeLists.txt
# =============================================================================


#############################################
# Utility command for edit_cache

build llama.cpp/CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build llama.cpp/edit_cache: phony llama.cpp/CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build llama.cpp/CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" --regenerate-during-build -S"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\src\main\cpp" -B"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build llama.cpp/rebuild_cache: phony llama.cpp/CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build llama.cpp/list_install_components: phony


#############################################
# Utility command for install

build llama.cpp/CMakeFiles/install.util: CUSTOM_COMMAND llama.cpp/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build llama.cpp/install: phony llama.cpp/CMakeFiles/install.util


#############################################
# Utility command for install/local

build llama.cpp/CMakeFiles/install/local.util: CUSTOM_COMMAND llama.cpp/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build llama.cpp/install/local: phony llama.cpp/CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build llama.cpp/CMakeFiles/install/strip.util: CUSTOM_COMMAND llama.cpp/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build llama.cpp/install/strip: phony llama.cpp/CMakeFiles/install/strip.util

# =============================================================================
# Write statements declared in CMakeLists.txt:
# C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/CMakeLists.txt
# =============================================================================


#############################################
# Utility command for edit_cache

build llama.cpp/ggml/CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build llama.cpp/ggml/edit_cache: phony llama.cpp/ggml/CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build llama.cpp/ggml/CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" --regenerate-during-build -S"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\src\main\cpp" -B"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build llama.cpp/ggml/rebuild_cache: phony llama.cpp/ggml/CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build llama.cpp/ggml/list_install_components: phony


#############################################
# Utility command for install

build llama.cpp/ggml/CMakeFiles/install.util: CUSTOM_COMMAND llama.cpp/ggml/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build llama.cpp/ggml/install: phony llama.cpp/ggml/CMakeFiles/install.util


#############################################
# Utility command for install/local

build llama.cpp/ggml/CMakeFiles/install/local.util: CUSTOM_COMMAND llama.cpp/ggml/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build llama.cpp/ggml/install/local: phony llama.cpp/ggml/CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build llama.cpp/ggml/CMakeFiles/install/strip.util: CUSTOM_COMMAND llama.cpp/ggml/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build llama.cpp/ggml/install/strip: phony llama.cpp/ggml/CMakeFiles/install/strip.util

# =============================================================================
# Write statements declared in CMakeLists.txt:
# C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/CMakeLists.txt
# =============================================================================

# =============================================================================
# Object build statements for SHARED_LIBRARY target ggml-base


#############################################
# Order-only phony target for ggml-base

build cmake_object_order_depends_target_ggml-base: phony || llama.cpp/ggml/src/CMakeFiles/ggml-base.dir

build llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o: C_COMPILER__ggml-base_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml.c || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"d82b7a7c1\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml.c.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -fno-limit-debug-info  -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -pthread -std=gnu11
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir

build llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o: CXX_COMPILER__ggml-base_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml.cpp || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"d82b7a7c1\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir

build llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o: C_COMPILER__ggml-base_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-alloc.c || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"d82b7a7c1\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml-alloc.c.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -fno-limit-debug-info  -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -pthread -std=gnu11
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir

build llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o: CXX_COMPILER__ggml-base_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-backend.cpp || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"d82b7a7c1\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml-backend.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir

build llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o: CXX_COMPILER__ggml-base_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-opt.cpp || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"d82b7a7c1\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml-opt.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir

build llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o: CXX_COMPILER__ggml-base_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-threading.cpp || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"d82b7a7c1\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml-threading.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir

build llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o: C_COMPILER__ggml-base_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-quants.c || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"d82b7a7c1\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml-quants.c.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -fno-limit-debug-info  -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -pthread -std=gnu11
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir

build llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o: CXX_COMPILER__ggml-base_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/gguf.cpp || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"d82b7a7c1\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\gguf.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir


# =============================================================================
# Link build statements for SHARED_LIBRARY target ggml-base


#############################################
# Link the shared library bin\libggml-base.so

build bin/libggml-base.so: CXX_SHARED_LIBRARY_LINKER__ggml-base_Debug llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o
  LANGUAGE_COMPILE_FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info
  LINK_FLAGS = -static-libstdc++ -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--no-undefined-version -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments
  LINK_LIBRARIES = -lm  -ldl  -pthread  -latomic -lm
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  POST_BUILD = cd .
  PRE_LINK = cd .
  SONAME = libggml-base.so
  SONAME_FLAG = -Wl,-soname,
  TARGET_FILE = bin\libggml-base.so
  TARGET_PDB = ggml-base.so.dbg

# =============================================================================
# Object build statements for SHARED_LIBRARY target ggml


#############################################
# Order-only phony target for ggml

build cmake_object_order_depends_target_ggml: phony || cmake_object_order_depends_target_ggml-base cmake_object_order_depends_target_ggml-cpu

build llama.cpp/ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o: CXX_COMPILER__ggml_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-backend-reg.cpp || cmake_object_order_depends_target_ggml
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml.dir\ggml-backend-reg.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml.dir


# =============================================================================
# Link build statements for SHARED_LIBRARY target ggml


#############################################
# Link the shared library bin\libggml.so

build bin/libggml.so: CXX_SHARED_LIBRARY_LINKER__ggml_Debug llama.cpp/ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o | bin/libggml-cpu.so bin/libggml-base.so || bin/libggml-base.so bin/libggml-cpu.so
  LANGUAGE_COMPILE_FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info
  LINK_FLAGS = -static-libstdc++ -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--no-undefined-version -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments
  LINK_LIBRARIES = bin/libggml-cpu.so  bin/libggml-base.so  -latomic -lm
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml.dir
  POST_BUILD = cd .
  PRE_LINK = cd .
  SONAME = libggml.so
  SONAME_FLAG = -Wl,-soname,
  TARGET_FILE = bin\libggml.so
  TARGET_PDB = ggml.so.dbg

# =============================================================================
# Object build statements for SHARED_LIBRARY target ggml-cpu


#############################################
# Order-only phony target for ggml-cpu

build cmake_object_order_depends_target_ggml-cpu: phony || cmake_object_order_depends_target_ggml-base

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o: C_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.c || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\ggml-cpu.c.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -fno-limit-debug-info  -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -std=gnu11
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\ggml-cpu.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/repack.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\repack.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/hbm.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\hbm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o: C_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/quants.c || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\quants.c.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -fno-limit-debug-info  -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -std=gnu11
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/traits.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\traits.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/amx/amx.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\amx\amx.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\amx

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/amx/mmq.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\amx\mmq.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\amx

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/binary-ops.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\binary-ops.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/unary-ops.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\unary-ops.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/vec.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\vec.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/ops.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\ops.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/llamafile/sgemm.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\llamafile\sgemm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\llamafile

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/arm/quants.c.o: C_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/arch/arm/quants.c || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\arch\arm\quants.c.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -fno-limit-debug-info  -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -std=gnu11
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\arch\arm

build llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/arm/repack.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/arch/arm/repack.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\arch\arm\repack.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/.." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\arch\arm


# =============================================================================
# Link build statements for SHARED_LIBRARY target ggml-cpu


#############################################
# Link the shared library bin\libggml-cpu.so

build bin/libggml-cpu.so: CXX_SHARED_LIBRARY_LINKER__ggml-cpu_Debug llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/arm/quants.c.o llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/arm/repack.cpp.o | bin/libggml-base.so || bin/libggml-base.so
  LANGUAGE_COMPILE_FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info
  LINK_FLAGS = -static-libstdc++ -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--no-undefined-version -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments
  LINK_LIBRARIES = bin/libggml-base.so  -latomic -lm
  OBJECT_DIR = llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  POST_BUILD = cd .
  PRE_LINK = cd .
  SONAME = libggml-cpu.so
  SONAME_FLAG = -Wl,-soname,
  TARGET_FILE = bin\libggml-cpu.so
  TARGET_PDB = ggml-cpu.so.dbg


#############################################
# Utility command for edit_cache

build llama.cpp/ggml/src/CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml\src" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build llama.cpp/ggml/src/edit_cache: phony llama.cpp/ggml/src/CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build llama.cpp/ggml/src/CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml\src" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" --regenerate-during-build -S"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\src\main\cpp" -B"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build llama.cpp/ggml/src/rebuild_cache: phony llama.cpp/ggml/src/CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build llama.cpp/ggml/src/list_install_components: phony


#############################################
# Utility command for install

build llama.cpp/ggml/src/CMakeFiles/install.util: CUSTOM_COMMAND llama.cpp/ggml/src/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml\src" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build llama.cpp/ggml/src/install: phony llama.cpp/ggml/src/CMakeFiles/install.util


#############################################
# Utility command for install/local

build llama.cpp/ggml/src/CMakeFiles/install/local.util: CUSTOM_COMMAND llama.cpp/ggml/src/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml\src" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build llama.cpp/ggml/src/install/local: phony llama.cpp/ggml/src/CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build llama.cpp/ggml/src/CMakeFiles/install/strip.util: CUSTOM_COMMAND llama.cpp/ggml/src/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml\src" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build llama.cpp/ggml/src/install/strip: phony llama.cpp/ggml/src/CMakeFiles/install/strip.util

# =============================================================================
# Write statements declared in CMakeLists.txt:
# C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/CMakeLists.txt
# =============================================================================


#############################################
# Utility command for edit_cache

build llama.cpp/ggml/src/ggml-cpu/CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml\src\ggml-cpu" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build llama.cpp/ggml/src/ggml-cpu/edit_cache: phony llama.cpp/ggml/src/ggml-cpu/CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build llama.cpp/ggml/src/ggml-cpu/CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml\src\ggml-cpu" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" --regenerate-during-build -S"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\src\main\cpp" -B"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build llama.cpp/ggml/src/ggml-cpu/rebuild_cache: phony llama.cpp/ggml/src/ggml-cpu/CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build llama.cpp/ggml/src/ggml-cpu/list_install_components: phony


#############################################
# Utility command for install

build llama.cpp/ggml/src/ggml-cpu/CMakeFiles/install.util: CUSTOM_COMMAND llama.cpp/ggml/src/ggml-cpu/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml\src\ggml-cpu" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build llama.cpp/ggml/src/ggml-cpu/install: phony llama.cpp/ggml/src/ggml-cpu/CMakeFiles/install.util


#############################################
# Utility command for install/local

build llama.cpp/ggml/src/ggml-cpu/CMakeFiles/install/local.util: CUSTOM_COMMAND llama.cpp/ggml/src/ggml-cpu/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml\src\ggml-cpu" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build llama.cpp/ggml/src/ggml-cpu/install/local: phony llama.cpp/ggml/src/ggml-cpu/CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build llama.cpp/ggml/src/ggml-cpu/CMakeFiles/install/strip.util: CUSTOM_COMMAND llama.cpp/ggml/src/ggml-cpu/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\ggml\src\ggml-cpu" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build llama.cpp/ggml/src/ggml-cpu/install/strip: phony llama.cpp/ggml/src/ggml-cpu/CMakeFiles/install/strip.util

# =============================================================================
# Write statements declared in CMakeLists.txt:
# C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/CMakeLists.txt
# =============================================================================

# =============================================================================
# Object build statements for SHARED_LIBRARY target llama


#############################################
# Order-only phony target for llama

build cmake_object_order_depends_target_llama: phony || cmake_object_order_depends_target_ggml cmake_object_order_depends_target_ggml-base cmake_object_order_depends_target_ggml-cpu

build llama.cpp/src/CMakeFiles/llama.dir/llama.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-adapter.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-adapter.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-adapter.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-arch.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-arch.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-arch.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-batch.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-batch.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-batch.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-chat.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-chat.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-chat.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-context.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-context.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-context.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-cparams.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-cparams.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-cparams.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-grammar.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-grammar.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-grammar.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-graph.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-graph.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-graph.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-hparams.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-hparams.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-hparams.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-impl.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-impl.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-impl.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-io.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-io.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-io.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-kv-cache.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-kv-cache.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-kv-cache-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-kv-cache-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-memory.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-memory.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-memory.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-memory-hybrid.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-memory-hybrid.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-memory-recurrent.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-memory-recurrent.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-mmap.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-mmap.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-mmap.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-model-loader.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-model-loader.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-model-loader.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-model-saver.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-model-saver.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-model-saver.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-model.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-model.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-model.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-quant.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-quant.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-quant.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-sampling.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-sampling.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-sampling.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/llama-vocab.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/llama-vocab.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\llama-vocab.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/unicode-data.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/unicode-data.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\unicode-data.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/unicode.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/unicode.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\unicode.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir

build llama.cpp/src/CMakeFiles/llama.dir/models/afmoe.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/afmoe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\afmoe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/apertus.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/apertus.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\apertus.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/arcee.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/arcee.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\arcee.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/arctic.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/arctic.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\arctic.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/arwkv7.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/arwkv7.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\arwkv7.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/baichuan.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/baichuan.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\baichuan.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/bailingmoe.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/bailingmoe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\bailingmoe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/bailingmoe2.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/bailingmoe2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\bailingmoe2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/bert.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/bert.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\bert.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/bitnet.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/bitnet.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\bitnet.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/bloom.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/bloom.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\bloom.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/chameleon.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/chameleon.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\chameleon.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/chatglm.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/chatglm.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\chatglm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/codeshell.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/codeshell.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\codeshell.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/cogvlm.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/cogvlm.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\cogvlm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/cohere2-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/cohere2-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\cohere2-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/command-r.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/command-r.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\command-r.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/dbrx.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/dbrx.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\dbrx.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/deci.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/deci.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\deci.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/deepseek.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/deepseek.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\deepseek.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/deepseek2.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/deepseek2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\deepseek2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/dots1.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/dots1.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\dots1.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/dream.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/dream.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\dream.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/ernie4-5-moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/ernie4-5-moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\ernie4-5-moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/ernie4-5.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/ernie4-5.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\ernie4-5.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/exaone.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/exaone.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\exaone.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/exaone4.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/exaone4.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\exaone4.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/falcon-h1.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/falcon-h1.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\falcon-h1.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/falcon.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/falcon.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\falcon.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/gemma-embedding.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/gemma-embedding.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\gemma-embedding.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/gemma.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/gemma.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\gemma.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/gemma2-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/gemma2-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\gemma2-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/gemma3-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/gemma3-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\gemma3-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/gemma3n-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/gemma3n-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\gemma3n-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/glm4-moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/glm4-moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\glm4-moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/glm4.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/glm4.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\glm4.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/gpt2.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/gpt2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\gpt2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/gptneox.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/gptneox.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\gptneox.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/granite-hybrid.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/granite-hybrid.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\granite-hybrid.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/granite.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/granite.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\granite.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/grok.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/grok.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\grok.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/grovemoe.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/grovemoe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\grovemoe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/hunyuan-dense.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/hunyuan-dense.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\hunyuan-dense.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/hunyuan-moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/hunyuan-moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\hunyuan-moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/internlm2.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/internlm2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\internlm2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/jais.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/jais.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\jais.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/jamba.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/jamba.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\jamba.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/lfm2.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/lfm2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\lfm2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/llada-moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/llada-moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\llada-moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/llada.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/llada.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\llada.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/llama-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/llama-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\llama-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/llama.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/llama.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\llama.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/mamba.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/mamba.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\mamba.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/minicpm3.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/minicpm3.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\minicpm3.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/minimax-m2.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/minimax-m2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\minimax-m2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/mpt.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/mpt.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\mpt.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/nemotron-h.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/nemotron-h.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\nemotron-h.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/nemotron.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/nemotron.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\nemotron.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/neo-bert.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/neo-bert.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\neo-bert.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/olmo.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/olmo.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\olmo.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/olmo2.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/olmo2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\olmo2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/olmoe.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/olmoe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\olmoe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/openai-moe-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/openai-moe-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\openai-moe-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/openelm.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/openelm.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\openelm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/orion.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/orion.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\orion.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/pangu-embedded.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/pangu-embedded.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\pangu-embedded.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/phi2.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/phi2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\phi2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/phi3.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/phi3.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\phi3.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/plamo.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/plamo.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\plamo.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/plamo2.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/plamo2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\plamo2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/plm.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/plm.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\plm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/qwen.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/qwen.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\qwen.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/qwen2.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/qwen2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\qwen2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/qwen2moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/qwen2moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\qwen2moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/qwen2vl.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/qwen2vl.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\qwen2vl.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/qwen3.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/qwen3.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\qwen3.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/qwen3vl.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/qwen3vl.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\qwen3vl.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/qwen3vl-moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/qwen3vl-moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\qwen3vl-moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/qwen3moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/qwen3moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\qwen3moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/qwen3next.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/qwen3next.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\qwen3next.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/refact.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/refact.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\refact.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/rnd1.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/rnd1.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\rnd1.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/rwkv6-base.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/rwkv6-base.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\rwkv6-base.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/rwkv6.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/rwkv6.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\rwkv6.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/rwkv6qwen2.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/rwkv6qwen2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\rwkv6qwen2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/rwkv7-base.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/rwkv7-base.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\rwkv7-base.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/rwkv7.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/rwkv7.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\rwkv7.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/seed-oss.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/seed-oss.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\seed-oss.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/smallthinker.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/smallthinker.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\smallthinker.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/smollm3.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/smollm3.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\smollm3.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/stablelm.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/stablelm.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\stablelm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/starcoder.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/starcoder.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\starcoder.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/starcoder2.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/starcoder2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\starcoder2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/t5-dec.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/t5-dec.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\t5-dec.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/t5-enc.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/t5-enc.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\t5-enc.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/wavtokenizer-dec.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/wavtokenizer-dec.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\wavtokenizer-dec.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/xverse.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/xverse.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\xverse.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models

build llama.cpp/src/CMakeFiles/llama.dir/models/graph-context-mamba.cpp.o: CXX_COMPILER__llama_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/models/graph-context-mamba.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = llama.cpp\src\CMakeFiles\llama.dir\models\graph-context-mamba.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = llama.cpp\src\CMakeFiles\llama.dir\models


# =============================================================================
# Link build statements for SHARED_LIBRARY target llama


#############################################
# Link the shared library bin\libllama.so

build bin/libllama.so: CXX_SHARED_LIBRARY_LINKER__llama_Debug llama.cpp/src/CMakeFiles/llama.dir/llama.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-adapter.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-arch.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-batch.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-chat.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-context.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-cparams.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-grammar.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-graph.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-hparams.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-impl.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-io.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-memory.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-mmap.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-model-loader.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-model-saver.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-model.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-quant.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-sampling.cpp.o llama.cpp/src/CMakeFiles/llama.dir/llama-vocab.cpp.o llama.cpp/src/CMakeFiles/llama.dir/unicode-data.cpp.o llama.cpp/src/CMakeFiles/llama.dir/unicode.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/afmoe.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/apertus.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/arcee.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/arctic.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/arwkv7.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/baichuan.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/bailingmoe.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/bailingmoe2.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/bert.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/bitnet.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/bloom.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/chameleon.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/chatglm.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/codeshell.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/cogvlm.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/cohere2-iswa.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/command-r.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/dbrx.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/deci.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/deepseek.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/deepseek2.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/dots1.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/dream.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/ernie4-5-moe.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/ernie4-5.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/exaone.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/exaone4.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/falcon-h1.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/falcon.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/gemma-embedding.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/gemma.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/gemma2-iswa.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/gemma3-iswa.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/gemma3n-iswa.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/glm4-moe.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/glm4.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/gpt2.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/gptneox.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/granite-hybrid.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/granite.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/grok.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/grovemoe.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/hunyuan-dense.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/hunyuan-moe.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/internlm2.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/jais.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/jamba.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/lfm2.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/llada-moe.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/llada.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/llama-iswa.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/llama.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/mamba.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/minicpm3.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/minimax-m2.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/mpt.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/nemotron-h.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/nemotron.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/neo-bert.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/olmo.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/olmo2.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/olmoe.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/openai-moe-iswa.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/openelm.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/orion.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/pangu-embedded.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/phi2.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/phi3.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/plamo.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/plamo2.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/plm.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/qwen.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/qwen2.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/qwen2moe.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/qwen2vl.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/qwen3.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/qwen3vl.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/qwen3vl-moe.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/qwen3moe.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/qwen3next.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/refact.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/rnd1.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/rwkv6-base.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/rwkv6.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/rwkv6qwen2.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/rwkv7-base.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/rwkv7.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/seed-oss.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/smallthinker.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/smollm3.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/stablelm.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/starcoder.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/starcoder2.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/t5-dec.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/t5-enc.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/wavtokenizer-dec.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/xverse.cpp.o llama.cpp/src/CMakeFiles/llama.dir/models/graph-context-mamba.cpp.o | bin/libggml.so bin/libggml-cpu.so bin/libggml-base.so || bin/libggml-base.so bin/libggml-cpu.so bin/libggml.so
  LANGUAGE_COMPILE_FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info
  LINK_FLAGS = -static-libstdc++ -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--no-undefined-version -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments
  LINK_LIBRARIES = bin/libggml.so  bin/libggml-cpu.so  bin/libggml-base.so  -latomic -lm
  OBJECT_DIR = llama.cpp\src\CMakeFiles\llama.dir
  POST_BUILD = cd .
  PRE_LINK = cd .
  SONAME = libllama.so
  SONAME_FLAG = -Wl,-soname,
  TARGET_FILE = bin\libllama.so
  TARGET_PDB = llama.so.dbg
  RSP_FILE = CMakeFiles\llama.rsp


#############################################
# Utility command for edit_cache

build llama.cpp/src/CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\src" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build llama.cpp/src/edit_cache: phony llama.cpp/src/CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build llama.cpp/src/CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\src" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" --regenerate-during-build -S"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\src\main\cpp" -B"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build llama.cpp/src/rebuild_cache: phony llama.cpp/src/CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build llama.cpp/src/list_install_components: phony


#############################################
# Utility command for install

build llama.cpp/src/CMakeFiles/install.util: CUSTOM_COMMAND llama.cpp/src/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\src" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build llama.cpp/src/install: phony llama.cpp/src/CMakeFiles/install.util


#############################################
# Utility command for install/local

build llama.cpp/src/CMakeFiles/install/local.util: CUSTOM_COMMAND llama.cpp/src/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\src" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build llama.cpp/src/install/local: phony llama.cpp/src/CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build llama.cpp/src/CMakeFiles/install/strip.util: CUSTOM_COMMAND llama.cpp/src/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\src" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build llama.cpp/src/install/strip: phony llama.cpp/src/CMakeFiles/install/strip.util

# =============================================================================
# Write statements declared in CMakeLists.txt:
# C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/CMakeLists.txt
# =============================================================================

# =============================================================================
# Object build statements for OBJECT_LIBRARY target build_info


#############################################
# Order-only phony target for build_info

build cmake_object_order_depends_target_build_info: phony || llama.cpp/common/CMakeFiles/build_info.dir

build llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o: CXX_COMPILER__build_info_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/.cxx/Debug/g5z3wa4k/arm64-v8a/llama.cpp/common/build-info.cpp || cmake_object_order_depends_target_build_info
  DEP_FILE = llama.cpp\common\CMakeFiles\build_info.dir\build-info.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  OBJECT_DIR = llama.cpp\common\CMakeFiles\build_info.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\build_info.dir



#############################################
# Object library build_info

build llama.cpp/common/build_info: phony llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o

# =============================================================================
# Object build statements for STATIC_LIBRARY target common


#############################################
# Order-only phony target for common

build cmake_object_order_depends_target_common: phony || cmake_object_order_depends_target_build_info cmake_object_order_depends_target_cpp-httplib cmake_object_order_depends_target_ggml cmake_object_order_depends_target_ggml-base cmake_object_order_depends_target_ggml-cpu cmake_object_order_depends_target_llama

build llama.cpp/common/CMakeFiles/common.dir/arg.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/arg.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\arg.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/chat-parser.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/chat-parser.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\chat-parser.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/chat-parser-xml-toolcall.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/chat-parser-xml-toolcall.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\chat-parser-xml-toolcall.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/chat.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/chat.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\chat.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/common.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/common.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\common.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/console.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/console.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\console.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/download.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/download.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\download.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/json-partial.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/json-partial.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\json-partial.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/json-schema-to-grammar.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\json-schema-to-grammar.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/llguidance.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/llguidance.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\llguidance.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/log.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/log.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\log.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/ngram-cache.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/ngram-cache.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\ngram-cache.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/regex-partial.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/regex-partial.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\regex-partial.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/sampling.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\sampling.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir

build llama.cpp/common/CMakeFiles/common.dir/speculative.cpp.o: CXX_COMPILER__common_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/speculative.cpp || cmake_object_order_depends_target_common
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -DLLAMA_USE_HTTPLIB
  DEP_FILE = llama.cpp\common\CMakeFiles\common.dir\speculative.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread
  INCLUDES = -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/." -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/../vendor" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/../include" -I"C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  OBJECT_FILE_DIR = llama.cpp\common\CMakeFiles\common.dir


# =============================================================================
# Link build statements for STATIC_LIBRARY target common


#############################################
# Link the static library llama.cpp\common\libcommon.a

build llama.cpp/common/libcommon.a: CXX_STATIC_LIBRARY_LINKER__common_Debug llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o llama.cpp/common/CMakeFiles/common.dir/arg.cpp.o llama.cpp/common/CMakeFiles/common.dir/chat-parser.cpp.o llama.cpp/common/CMakeFiles/common.dir/chat-parser-xml-toolcall.cpp.o llama.cpp/common/CMakeFiles/common.dir/chat.cpp.o llama.cpp/common/CMakeFiles/common.dir/common.cpp.o llama.cpp/common/CMakeFiles/common.dir/console.cpp.o llama.cpp/common/CMakeFiles/common.dir/download.cpp.o llama.cpp/common/CMakeFiles/common.dir/json-partial.cpp.o llama.cpp/common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o llama.cpp/common/CMakeFiles/common.dir/llguidance.cpp.o llama.cpp/common/CMakeFiles/common.dir/log.cpp.o llama.cpp/common/CMakeFiles/common.dir/ngram-cache.cpp.o llama.cpp/common/CMakeFiles/common.dir/regex-partial.cpp.o llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o llama.cpp/common/CMakeFiles/common.dir/speculative.cpp.o || bin/libggml-base.so bin/libggml-cpu.so bin/libggml.so bin/libllama.so llama.cpp/common/build_info llama.cpp/vendor/cpp-httplib/libcpp-httplib.a bin/libllama.so bin/libggml.so bin/libggml-cpu.so bin/libggml-base.so
  LANGUAGE_COMPILE_FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info
  OBJECT_DIR = llama.cpp\common\CMakeFiles\common.dir
  POST_BUILD = cd .
  PRE_LINK = cd .
  TARGET_FILE = llama.cpp\common\libcommon.a
  TARGET_PDB = common.a.dbg


#############################################
# Utility command for edit_cache

build llama.cpp/common/CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\common" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build llama.cpp/common/edit_cache: phony llama.cpp/common/CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build llama.cpp/common/CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\common" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" --regenerate-during-build -S"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\src\main\cpp" -B"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build llama.cpp/common/rebuild_cache: phony llama.cpp/common/CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build llama.cpp/common/list_install_components: phony


#############################################
# Utility command for install

build llama.cpp/common/CMakeFiles/install.util: CUSTOM_COMMAND llama.cpp/common/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\common" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build llama.cpp/common/install: phony llama.cpp/common/CMakeFiles/install.util


#############################################
# Utility command for install/local

build llama.cpp/common/CMakeFiles/install/local.util: CUSTOM_COMMAND llama.cpp/common/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\common" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build llama.cpp/common/install/local: phony llama.cpp/common/CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build llama.cpp/common/CMakeFiles/install/strip.util: CUSTOM_COMMAND llama.cpp/common/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\common" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build llama.cpp/common/install/strip: phony llama.cpp/common/CMakeFiles/install/strip.util

# =============================================================================
# Write statements declared in CMakeLists.txt:
# C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/CMakeLists.txt
# =============================================================================

# =============================================================================
# Object build statements for STATIC_LIBRARY target cpp-httplib


#############################################
# Order-only phony target for cpp-httplib

build cmake_object_order_depends_target_cpp-httplib: phony || llama.cpp/vendor/cpp-httplib/CMakeFiles/cpp-httplib.dir

build llama.cpp/vendor/cpp-httplib/CMakeFiles/cpp-httplib.dir/httplib.cpp.o: CXX_COMPILER__cpp-httplib_Debug C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/vendor/cpp-httplib/httplib.cpp || cmake_object_order_depends_target_cpp-httplib
  DEFINES = -DCPPHTTPLIB_FORM_URL_ENCODED_PAYLOAD_MAX_LENGTH=1048576 -DCPPHTTPLIB_LISTEN_BACKLOG=512 -DCPPHTTPLIB_REQUEST_URI_MAX_LENGTH=32768 -DCPPHTTPLIB_TCP_NODELAY=1
  DEP_FILE = llama.cpp\vendor\cpp-httplib\CMakeFiles\cpp-httplib.dir\httplib.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -w -pthread
  OBJECT_DIR = llama.cpp\vendor\cpp-httplib\CMakeFiles\cpp-httplib.dir
  OBJECT_FILE_DIR = llama.cpp\vendor\cpp-httplib\CMakeFiles\cpp-httplib.dir


# =============================================================================
# Link build statements for STATIC_LIBRARY target cpp-httplib


#############################################
# Link the static library llama.cpp\vendor\cpp-httplib\libcpp-httplib.a

build llama.cpp/vendor/cpp-httplib/libcpp-httplib.a: CXX_STATIC_LIBRARY_LINKER__cpp-httplib_Debug llama.cpp/vendor/cpp-httplib/CMakeFiles/cpp-httplib.dir/httplib.cpp.o
  LANGUAGE_COMPILE_FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info
  OBJECT_DIR = llama.cpp\vendor\cpp-httplib\CMakeFiles\cpp-httplib.dir
  POST_BUILD = cd .
  PRE_LINK = cd .
  TARGET_FILE = llama.cpp\vendor\cpp-httplib\libcpp-httplib.a
  TARGET_PDB = cpp-httplib.a.dbg


#############################################
# Utility command for edit_cache

build llama.cpp/vendor/cpp-httplib/CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\vendor\cpp-httplib" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build llama.cpp/vendor/cpp-httplib/edit_cache: phony llama.cpp/vendor/cpp-httplib/CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build llama.cpp/vendor/cpp-httplib/CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\vendor\cpp-httplib" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" --regenerate-during-build -S"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\src\main\cpp" -B"C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build llama.cpp/vendor/cpp-httplib/rebuild_cache: phony llama.cpp/vendor/cpp-httplib/CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build llama.cpp/vendor/cpp-httplib/list_install_components: phony


#############################################
# Utility command for install

build llama.cpp/vendor/cpp-httplib/CMakeFiles/install.util: CUSTOM_COMMAND llama.cpp/vendor/cpp-httplib/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\vendor\cpp-httplib" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build llama.cpp/vendor/cpp-httplib/install: phony llama.cpp/vendor/cpp-httplib/CMakeFiles/install.util


#############################################
# Utility command for install/local

build llama.cpp/vendor/cpp-httplib/CMakeFiles/install/local.util: CUSTOM_COMMAND llama.cpp/vendor/cpp-httplib/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\vendor\cpp-httplib" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build llama.cpp/vendor/cpp-httplib/install/local: phony llama.cpp/vendor/cpp-httplib/CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build llama.cpp/vendor/cpp-httplib/CMakeFiles/install/strip.util: CUSTOM_COMMAND llama.cpp/vendor/cpp-httplib/all
  COMMAND = cmd.exe /C "cd /D "C:\Users\NIHARIKA KUJUR\AndroidStudioProjects\Invisibleinsight\app\.cxx\Debug\g5z3wa4k\arm64-v8a\llama.cpp\vendor\cpp-httplib" && "C:\Users\NIHARIKA KUJUR\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe" -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build llama.cpp/vendor/cpp-httplib/install/strip: phony llama.cpp/vendor/cpp-httplib/CMakeFiles/install/strip.util

# =============================================================================
# Target aliases.

build build_info: phony llama.cpp/common/build_info

build common: phony llama.cpp/common/libcommon.a

build cpp-httplib: phony llama.cpp/vendor/cpp-httplib/libcpp-httplib.a

build ggml: phony bin/libggml.so

build ggml-base: phony bin/libggml-base.so

build ggml-cpu: phony bin/libggml-cpu.so

build libcommon.a: phony llama.cpp/common/libcommon.a

build libcpp-httplib.a: phony llama.cpp/vendor/cpp-httplib/libcpp-httplib.a

build libggml-base.so: phony bin/libggml-base.so

build libggml-cpu.so: phony bin/libggml-cpu.so

build libggml.so: phony bin/libggml.so

build libllama.so: phony bin/libllama.so

build libnative-lib.so: phony C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/build/intermediates/cxx/Debug/g5z3wa4k/obj/arm64-v8a/libnative-lib.so

build llama: phony bin/libllama.so

build native-lib: phony C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/build/intermediates/cxx/Debug/g5z3wa4k/obj/arm64-v8a/libnative-lib.so

# =============================================================================
# Folder targets.

# =============================================================================

#############################################
# Folder: C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/.cxx/Debug/g5z3wa4k/arm64-v8a

build all: phony C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/build/intermediates/cxx/Debug/g5z3wa4k/obj/arm64-v8a/libnative-lib.so llama.cpp/all

# =============================================================================

#############################################
# Folder: C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/.cxx/Debug/g5z3wa4k/arm64-v8a/llama.cpp

build llama.cpp/all: phony llama.cpp/ggml/all llama.cpp/src/all llama.cpp/common/all llama.cpp/vendor/cpp-httplib/all

# =============================================================================

#############################################
# Folder: C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/.cxx/Debug/g5z3wa4k/arm64-v8a/llama.cpp/common

build llama.cpp/common/all: phony llama.cpp/common/build_info llama.cpp/common/libcommon.a

# =============================================================================

#############################################
# Folder: C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/.cxx/Debug/g5z3wa4k/arm64-v8a/llama.cpp/ggml

build llama.cpp/ggml/all: phony llama.cpp/ggml/src/all

# =============================================================================

#############################################
# Folder: C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/.cxx/Debug/g5z3wa4k/arm64-v8a/llama.cpp/ggml/src

build llama.cpp/ggml/src/all: phony bin/libggml-base.so bin/libggml.so bin/libggml-cpu.so llama.cpp/ggml/src/ggml-cpu/all

# =============================================================================

#############################################
# Folder: C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/.cxx/Debug/g5z3wa4k/arm64-v8a/llama.cpp/ggml/src/ggml-cpu

build llama.cpp/ggml/src/ggml-cpu/all: phony

# =============================================================================

#############################################
# Folder: C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/.cxx/Debug/g5z3wa4k/arm64-v8a/llama.cpp/src

build llama.cpp/src/all: phony bin/libllama.so

# =============================================================================

#############################################
# Folder: C:/Users/NIHARIKA KUJUR/AndroidStudioProjects/Invisibleinsight/app/.cxx/Debug/g5z3wa4k/arm64-v8a/llama.cpp/vendor/cpp-httplib

build llama.cpp/vendor/cpp-httplib/all: phony llama.cpp/vendor/cpp-httplib/libcpp-httplib.a

# =============================================================================
# Built-in targets


#############################################
# Re-run CMake if any of its inputs changed.

build build.ninja: RERUN_CMAKE | C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/.git/index C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/cmake/build-info.cmake C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/cmake/common.cmake C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/cmake/llama-config.cmake.in C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/cmake/llama.pc.in C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/build-info.cpp.in C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/cmake/common.cmake C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/cmake/ggml-config.cmake.in C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/vendor/cpp-httplib/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/BasicConfigVersion-SameMajorVersion.cmake.in C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeASMInformation.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCInformation.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCXXInformation.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCheckCompilerFlagCommonPatterns.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCommonLanguageInclude.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeGenericSystem.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeInitializeConfigs.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeLanguageInformation.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakePackageConfigHelpers.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeSystemSpecificInformation.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeSystemSpecificInitialize.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckCSourceCompiles.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckCXXCompilerFlag.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckCXXSourceCompiles.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckIncludeFile.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckIncludeFileCXX.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckLibraryExists.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/CMakeCommonCompilerMacros.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-ASM.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-C.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-CXX.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/GNU.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindGit.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindPackageMessage.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindThreads.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/GNUInstallDirs.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Internal/CheckCompilerFlag.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Internal/CheckSourceCompiles.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang-ASM.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang-C.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang-CXX.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Initialize.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Linux.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/UnixPaths.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/WriteBasicConfigVersionFile.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/android-legacy.toolchain.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/android.toolchain.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/flags.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/hooks/pre/Android-Clang.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/hooks/pre/Android-Initialize.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/hooks/pre/Android.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/platforms.cmake CMakeCache.txt CMakeFiles/3.22.1-g37088a8-dirty/CMakeASMCompiler.cmake CMakeFiles/3.22.1-g37088a8-dirty/CMakeCCompiler.cmake CMakeFiles/3.22.1-g37088a8-dirty/CMakeCXXCompiler.cmake CMakeFiles/3.22.1-g37088a8-dirty/CMakeSystem.cmake
  pool = console


#############################################
# A missing CMake input file is not an error.

build C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/.git/index C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/cmake/build-info.cmake C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/cmake/common.cmake C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/cmake/llama-config.cmake.in C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/cmake/llama.pc.in C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/common/build-info.cpp.in C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/cmake/common.cmake C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/cmake/ggml-config.cmake.in C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/ggml/src/ggml-cpu/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/src/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AndroidStudioProjects/Invisibleinsight/app/src/main/cpp/llama.cpp/vendor/cpp-httplib/CMakeLists.txt C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/BasicConfigVersion-SameMajorVersion.cmake.in C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeASMInformation.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCInformation.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCXXInformation.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCheckCompilerFlagCommonPatterns.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCommonLanguageInclude.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeGenericSystem.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeInitializeConfigs.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeLanguageInformation.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakePackageConfigHelpers.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeSystemSpecificInformation.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeSystemSpecificInitialize.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckCSourceCompiles.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckCXXCompilerFlag.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckCXXSourceCompiles.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckIncludeFile.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckIncludeFileCXX.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckLibraryExists.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/CMakeCommonCompilerMacros.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-ASM.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-C.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-CXX.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/GNU.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindGit.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindPackageMessage.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindThreads.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/GNUInstallDirs.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Internal/CheckCompilerFlag.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Internal/CheckSourceCompiles.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang-ASM.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang-C.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang-CXX.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Initialize.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Linux.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/UnixPaths.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/WriteBasicConfigVersionFile.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/android-legacy.toolchain.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/android.toolchain.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/flags.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/hooks/pre/Android-Clang.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/hooks/pre/Android-Initialize.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/hooks/pre/Android.cmake C$:/Users/NIHARIKA$ KUJUR/AppData/Local/Android/Sdk/ndk/26.3.11579264/build/cmake/platforms.cmake CMakeCache.txt CMakeFiles/3.22.1-g37088a8-dirty/CMakeASMCompiler.cmake CMakeFiles/3.22.1-g37088a8-dirty/CMakeCCompiler.cmake CMakeFiles/3.22.1-g37088a8-dirty/CMakeCXXCompiler.cmake CMakeFiles/3.22.1-g37088a8-dirty/CMakeSystem.cmake: phony


#############################################
# Clean all the built files.

build clean: CLEAN


#############################################
# Print all primary targets available.

build help: HELP


#############################################
# Make the all target the default.

default all
